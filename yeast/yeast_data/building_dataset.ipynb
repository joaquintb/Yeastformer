{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bulding Geneformer-Like Dataset From Yeast Master Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building .loom file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacing NaNs by 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/original_yeast_master_matrix_sgd_copy.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(file_path, sep='\\t', index_col=0) # Important to keep sep='\\t', since that's how it was saved \n",
    "\n",
    "# print(df.shape)\n",
    "\n",
    "# Replace NaNs with 0\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Save the cleaned CSV\n",
    "df.to_csv(file_path, sep='\\t')\n",
    "\n",
    "print(\"NaNs replaced with 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Translating to .loom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import loompy\n",
    "\n",
    "input_file_path = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/original_yeast_master_matrix_sgd_copy.csv\"\n",
    "output_file_path = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/yeast_master_matrix_sgd.loom\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(input_file_path, sep='\\t', index_col=0) # Important to keep sep='\\t', since that's how it was saved \n",
    "\n",
    "# Compute total read counts for each experiment (equivalent to cell in geneformer)\n",
    "n_counts = df.sum(axis=0).astype(np.float32)  # Sum across genes for each column \n",
    "\n",
    "# Prepare row attributes (Gene IDs â†’ Ensembl IDs assumed to be index)\n",
    "row_attrs = {\"ensembl_id\": df.index.tolist()}  # Ensure index has Ensembl IDs\n",
    "\n",
    "# Prepare column attributes (Cells & their total read counts)\n",
    "col_attrs = {\n",
    "    # \"exp_name\": df.columns.tolist(),  # Experiment names\n",
    "    \"n_counts\": n_counts.values,   # Total counts per column (experiment)\n",
    "}\n",
    "\n",
    "# Convert DataFrame to Loom format & save\n",
    "loompy.create(output_file_path, df.values.astype(np.float32), row_attrs, col_attrs)\n",
    "\n",
    "print(f\"Loom file saved as: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)  # Should print something like 1.26.4\n",
    "\n",
    "# Had to downgrade numpy < 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Verifying .loom file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loompy\n",
    "\n",
    "input_loom_file_path = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/yeast_master_matrix_sgd.loom\"\n",
    "\n",
    "with loompy.connect(input_loom_file_path) as ds:\n",
    "    # Print general metadata\n",
    "    print(\"Row attributes:\", ds.ra.keys())  # Should contain 'ensembl_id'\n",
    "    print(\"Column attributes:\", ds.ca.keys())  # Should contain 'n_counts'\n",
    "    print(\"Data shape (genes x exp columns):\", ds.shape)\n",
    "\n",
    "    # Print first 5 genes (rows) and their attributes\n",
    "    print(\"\\nFirst 5 Row Attributes:\")\n",
    "    for key in ds.ra.keys():\n",
    "        print(f\"{key}: {ds.ra[key][:5]}\")  # Print first 5 values of each row attribute\n",
    "\n",
    "    # print(f\"exp_name: {ds.ca['exp_name'][:1]}\")\n",
    "    print(f\"n_counts: {ds.ca['n_counts'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Dictionaries "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokens Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load example to see the intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Path to the token dictionary file\n",
    "token_dict_file = \"/home/logs/jtorresb/Geneformer/geneformer/token_dictionary_gc95M.pkl\"\n",
    "\n",
    "# Function to inspect the token dictionary\n",
    "def inspect_token_dictionary(file_path, num_samples=10):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        token_dict = pickle.load(f)\n",
    "    \n",
    "    print(f\"Token dictionary type: {type(token_dict)}\")\n",
    "    print(f\"Total tokens: {len(token_dict)}\")\n",
    "    print(\"First 10 token entries:\")\n",
    "    sample_items = list(token_dict.items())[:num_samples]\n",
    "    for key, value in sample_items:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Run the inspection\n",
    "inspect_token_dictionary(token_dict_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Generating Token Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# File paths\n",
    "csv_file = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/original_yeast_master_matrix_sgd.csv\"\n",
    "output_pkl = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/yeast_token_dict.pkl\"\n",
    "\n",
    "# Load CSV (Ensure YORFs are the index)\n",
    "df = pd.read_csv(csv_file, sep='\\t', index_col=0)\n",
    "\n",
    "# Extract yeast ORFs (YORFs) from index\n",
    "yorfs = df.index.tolist()\n",
    "\n",
    "# Optional: Sort alphabetically for consistency\n",
    "yorfs.sort()\n",
    "\n",
    "# Initialize token dictionary with special tokens\n",
    "token_dict = {\n",
    "    \"<pad>\": 0,\n",
    "    \"<mask>\": 1,\n",
    "    \"<cls>\": 2,\n",
    "    \"<eos>\": 3,\n",
    "}\n",
    "\n",
    "# Assign unique token IDs starting from 4\n",
    "for i, gene_id in enumerate(yorfs, start=4):\n",
    "    token_dict[gene_id] = i\n",
    "\n",
    "# Save dictionary as a pickle file\n",
    "with open(output_pkl, \"wb\") as f:\n",
    "    pickle.dump(token_dict, f)\n",
    "\n",
    "print(f\"Token dictionary saved as: {output_pkl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Medians Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inspecting example first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Path to the median dictionary file\n",
    "median_dict_file = \"/home/logs/jtorresb/Geneformer/geneformer/gene_median_dictionary_gc95M.pkl\"\n",
    "\n",
    "# Function to inspect the median dictionary\n",
    "def inspect_median_dictionary(file_path, num_samples=10):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        median_dict = pickle.load(f)\n",
    "    \n",
    "    print(f\"Median dictionary type: {type(median_dict)}\")\n",
    "    print(f\"Total genes in dictionary: {len(median_dict)}\")\n",
    "    print(\"First 10 median entries:\")\n",
    "    sample_items = list(median_dict.items())[:num_samples]\n",
    "    for key, value in sample_items:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Run the inspection\n",
    "inspect_median_dictionary(median_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# File paths\n",
    "csv_file = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/original_yeast_master_matrix_sgd_copy.csv\" # Copy already replaced NaNs by 0s\n",
    "output_pkl = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/yeast_median_dict.pkl\"\n",
    "\n",
    "# Load CSV (genes as index, experiments as columns)\n",
    "df = pd.read_csv(csv_file, sep='\\t', index_col=0)\n",
    "\n",
    "# Compute nonzero medians for each gene\n",
    "median_dict = {}\n",
    "for gene in df.index:\n",
    "    nonzero_values = df.loc[gene][df.loc[gene] != 0]  # Ignore zeros\n",
    "    if not nonzero_values.empty:\n",
    "        median_dict[gene] = np.median(nonzero_values)  # Compute median\n",
    "    else:\n",
    "        median_dict[gene] = 0  # If all values are zero, set median to 0\n",
    "\n",
    "# Save dictionary as a pickle file\n",
    "with open(output_pkl, \"wb\") as f:\n",
    "    pickle.dump(median_dict, f)\n",
    "\n",
    "print(f\"Median dictionary saved as: {output_pkl}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
