{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Yeast Master Matrix From Microarray Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Misc Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GWEIGHTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# List to store file names with non-uniform GWEIGHT values\n",
    "files_with_non_uniform_gweight = []\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if the 'GWEIGHT' column exists\n",
    "            if 'GWEIGHT' in df.columns:\n",
    "                # Check if all values in 'GWEIGHT' are equal to 1\n",
    "                if not (df['GWEIGHT'] == 1).all():\n",
    "                    files_with_non_uniform_gweight.append(file_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the results\n",
    "if files_with_non_uniform_gweight:\n",
    "    print(\"Files with non-uniform GWEIGHT values:\")\n",
    "    for file in files_with_non_uniform_gweight:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"All files have GWEIGHT values uniformly equal to 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Number of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Counter for total number of experiment columns\n",
    "total_experiment_columns = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Count the experiment columns (excluding 'GWEIGHT', 'NAME', 'IDENTIFIER', 'Description', etc.)\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME', 'IDENTIFIER', 'Description']]\n",
    "            total_experiment_columns += len(experiment_columns)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total number of experiment columns\n",
    "print(f\"Total number of experiment columns across all files: {total_experiment_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Files with More Genes than Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Threshold for the size of the yeast genome\n",
    "threshold = 7337\n",
    "\n",
    "# Counter for files with unique rows exceeding the threshold\n",
    "count_exceeding_files = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Find the number of unique rows\n",
    "            unique_count = df.drop_duplicates().shape[0]\n",
    "\n",
    "            # Check if the unique count exceeds the threshold\n",
    "            if unique_count > threshold:\n",
    "                count_exceeding_files += 1\n",
    "\n",
    "                # Count rows where the YORF (index) starts with 'SGD'\n",
    "                sgd_count = sum(df.index.astype(str).str.startswith('SGD'))\n",
    "\n",
    "                print(f\"File: {file_name}, Number of unique rows: {unique_count}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total count of files exceeding the threshold\n",
    "print(f\"Number of files with unique rows larger than {threshold}: {count_exceeding_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalizing Columns in Each .pcl File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Exclude non-experiment columns from normalization\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME']]\n",
    "\n",
    "            # Cast the experiment columns to float32\n",
    "            df[experiment_columns] = df[experiment_columns].astype('float32')\n",
    "\n",
    "            # Initialize the scaler\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "            # Apply z-score normalization for each experiment column\n",
    "            df[experiment_columns] = scaler.fit_transform(df[experiment_columns])\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Translating All Indexes to YORFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with SGD indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 556 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files and the all_yeast_genes.tsv file\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the all_yeast_genes.tsv to create the mapping dictionary\n",
    "genes_df = pd.read_csv(genes_file, sep='\\t')\n",
    "gene_mapping = dict(zip(genes_df['Gene > Primary DBID'], genes_df['Gene > Systematic Name']))\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Replace index values that start with 'SGD' using the mapping dictionary\n",
    "            df.index = df.index.to_series().apply(lambda x: gene_mapping.get(x, x) if x.startswith('SGD') else x)\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 556 files.\n",
      "Found 'SGD' indices in 0 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_checked = 0\n",
    "sgd_found = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if any index starts with 'SGD'\n",
    "            if df.index.str.startswith('SGD').any():\n",
    "                print(f\"Found 'SGD' in indices of file: {file_name}\")\n",
    "                sgd_found += 1\n",
    "\n",
    "            files_checked += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Checked {files_checked} files.\")\n",
    "print(f\"Found 'SGD' indices in {sgd_found} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are close to the size of the genome, but still having some extra rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create sets for faster lookups\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'])\n",
    "\n",
    "all_problematic_genes = set()\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Find problematic indexes\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index\n",
    "                if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            # Print problematic file and indexes\n",
    "            if problematic_indexes:\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "                all_problematic_genes.update(problematic_indexes)\n",
    "                print('-----------------------------------')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(len(all_problematic_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For simplicity, let's just discard the remaining since we would need to manually look up everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Get the set of valid systematic names, ensuring case insensitivity\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'].str.upper())\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows with indexes not in the valid systematic names\n",
    "            invalid_indexes = [index for index in pcl_df.index if index.upper() not in valid_systematic_names]\n",
    "\n",
    "            # If invalid rows are found, drop them\n",
    "            if invalid_indexes:\n",
    "                pcl_df.drop(index=invalid_indexes, inplace=True)\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "                print(f\"File '{file_name}' updated: Removed {len(invalid_indexes)} invalid rows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem: if not treated, master matrix would have two different names for the same gene and the matrix will grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the normalized folder\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Initialize a flag to indicate whether the index is found\n",
    "found = False\n",
    "\n",
    "# Process each .pcl file in the folder\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if 'YJR084W' exists as an index\n",
    "            if 'YJR084W' in pcl_df.index:\n",
    "                print(f\"Found 'YJR084W' in file: {file_name}\")\n",
    "                found = True\n",
    "                break  # Stop the loop as the index is found\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# If not found in any file, notify\n",
    "if not found:\n",
    "    print(\"'YJR084W' not found in any file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's look for repeated YORF rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the normalized folder\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Flag to stop processing if a problematic file is found\n",
    "problem_found = False\n",
    "\n",
    "# Process each .pcl file in the folder\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check for duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].tolist()\n",
    "            if duplicate_indexes:\n",
    "                print(f\"Problematic file: {file_name}\")\n",
    "                print(f\"Duplicate indexes: {duplicate_indexes}\")\n",
    "                # problem_found = True\n",
    "                # break  # Stop the loop at the first problematic file\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# If no problematic file is found, notify\n",
    "if not problem_found:\n",
    "    print(\"All files have unique row indexes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apparently again rows are repeated, the corresponding YORF contains the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Extract valid Gene > Systematic Names\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'])\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory)):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify problematic indexes\n",
    "            problematic_indexes = [index for index in pcl_df.index if index not in valid_systematic_names]\n",
    "\n",
    "            # Store problematic genes that fail the condition\n",
    "            unsatisfied_genes = []\n",
    "\n",
    "            # Iterate over problematic indexes\n",
    "            for problematic_index in problematic_indexes:\n",
    "                # Get experimental data for the problematic row, excluding NAME and GWEIGHT\n",
    "                problematic_data = pcl_df.loc[problematic_index].drop(['NAME', 'GWEIGHT'], errors='ignore')\n",
    "\n",
    "                # Check for matching rows with indexes starting with 'Y'\n",
    "                matching_rows = pcl_df[\n",
    "                    pcl_df.index.str.startswith('Y')\n",
    "                    & (pcl_df.drop(columns=['NAME', 'GWEIGHT'], errors='ignore') == problematic_data).all(axis=1)\n",
    "                ]\n",
    "\n",
    "                # If no matching row is found, add to unsatisfied list\n",
    "                if matching_rows.empty:\n",
    "                    unsatisfied_genes.append(problematic_index)\n",
    "\n",
    "            # If there are unsatisfied genes, print the file and the genes\n",
    "            if unsatisfied_genes:\n",
    "                print(f\"File ({file_count +1}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Problematic genes without matching 'Y' rows: {len(unsatisfied_genes)}\")\n",
    "                print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For now, let's remove the problematic index if YORF available and same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to directories and files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "gene_mapping_path = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the valid systematic names from the mapping file\n",
    "gene_mapping_df = pd.read_csv(gene_mapping_path, sep='\\t')\n",
    "valid_systematic_names = set(gene_mapping_df['Gene > Systematic Name'].dropna())\n",
    "\n",
    "# Process each .pcl file\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory), start=1):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify problematic indexes (not in valid systematic names)\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            if problematic_indexes:\n",
    "                print(f\"Processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "\n",
    "                # Check if problematic indexes have matching valid systematic name rows\n",
    "                rows_to_drop = []\n",
    "                for problem_index in problematic_indexes:\n",
    "                    # Check if there is a matching row with valid systematic name\n",
    "                    matching_rows = pcl_df.loc[\n",
    "                        pcl_df.index.isin(valid_systematic_names) & \n",
    "                        (pcl_df.loc[problem_index].drop(['NAME', 'GWEIGHT'], errors='ignore') == pcl_df.drop(['NAME', 'GWEIGHT'], axis=1, errors='ignore')).all(axis=1)\n",
    "                    ]\n",
    "\n",
    "                    # If a matching row exists, mark the problematic index for removal\n",
    "                    if not matching_rows.empty:\n",
    "                        rows_to_drop.append(problem_index)\n",
    "\n",
    "                # Remove the problematic rows and overwrite the file\n",
    "                if rows_to_drop:\n",
    "                    pcl_df = pcl_df.drop(index=rows_to_drop)\n",
    "                    pcl_df.to_csv(file_path, sep='\\t')\n",
    "                    print(f\"Fixed and overwritten file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                else:\n",
    "                    print(f\"No matching rows found for problematic indexes in file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For those in Standard Name, replace by YORF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create a dictionary mapping Gene > Standard Name to Gene > Systematic Name (case-insensitive)\n",
    "standard_to_systematic = {\n",
    "    standard.upper(): systematic.upper() \n",
    "    for standard, systematic in zip(\n",
    "        yeast_genes_df['Gene > Standard Name'].dropna(), \n",
    "        yeast_genes_df['Gene > Systematic Name'].dropna()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Flag to check if the file was modified\n",
    "            modified = False\n",
    "\n",
    "            # Create a new index list\n",
    "            new_index = []\n",
    "            for index in pcl_df.index:\n",
    "                # Check if the index is problematic (doesn't start with 'Y' or 'Q')\n",
    "                if not (index.upper().startswith('Y') or index.upper().startswith('Q')):\n",
    "                    # Convert index to uppercase and check in dictionary\n",
    "                    upper_index = index.upper()\n",
    "                    if upper_index in standard_to_systematic:\n",
    "                        # Replace the index with the corresponding Gene > Systematic Name\n",
    "                        new_index.append(standard_to_systematic[upper_index])\n",
    "                        modified = True\n",
    "                    else:\n",
    "                        # Keep the index as is if no mapping exists\n",
    "                        new_index.append(index)\n",
    "                else:\n",
    "                    new_index.append(index)\n",
    "\n",
    "            # Update the index of the DataFrame if modified\n",
    "            if modified:\n",
    "                pcl_df.index = new_index\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "\n",
    "                print(f\"File '{file_name}' updated successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now all indexes are correct YORFs, but we need to deal with duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].unique()\n",
    "            \n",
    "            if len(duplicate_indexes) > 0:\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Number of duplicate indexes: {len(duplicate_indexes)}\")\n",
    "\n",
    "                # Check if the rows match for each duplicate index\n",
    "                for dup_index in duplicate_indexes:\n",
    "                    duplicate_rows = pcl_df.loc[dup_index]\n",
    "                    \n",
    "                    # Count occurrences of the duplicate index\n",
    "                    num_duplicates = len(duplicate_rows) if isinstance(duplicate_rows, pd.DataFrame) else 1\n",
    "                    \n",
    "                    # Handle duplicates with 3 or more occurrences\n",
    "                    if num_duplicates >= 3:\n",
    "                        print(f\"  - Gene '{dup_index}' has {num_duplicates} duplicates.\")\n",
    "                    \n",
    "                    # Check if the rows match\n",
    "                    if isinstance(duplicate_rows, pd.DataFrame):\n",
    "                        experiment_columns = duplicate_rows.drop(columns=['NAME', 'GWEIGHT'], errors='ignore')\n",
    "                        \n",
    "                        # Check if all rows are identical\n",
    "                        rows_match = experiment_columns.nunique().sum() == experiment_columns.shape[1]\n",
    "                        \n",
    "                        if rows_match:\n",
    "                            print(f\"    - Duplicate index '{dup_index}' has matching rows.\")\n",
    "                        else:\n",
    "                            print(f\"    - Duplicate index '{dup_index}' has non-matching rows.\")\n",
    "                    else:\n",
    "                        print(f\"  - Duplicate index '{dup_index}' has only one row (unexpected).\")\n",
    "\n",
    "                print('\\n')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing direct duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Drop duplicates based on the index and experimental columns (excluding NAME and GWEIGHT)\n",
    "            experimental_columns = pcl_df.drop(columns=['NAME', 'GWEIGHT'], errors='ignore')\n",
    "            deduplicated_df = pcl_df.loc[~experimental_columns.index.duplicated(keep='first')]\n",
    "\n",
    "            # Save the deduplicated DataFrame back to the same file\n",
    "            deduplicated_df.to_csv(pcl_file_path, sep='\\t')\n",
    "            print(f\"Duplicates removed for file: {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].unique()\n",
    "            \n",
    "            # Print if the file has duplicates or not\n",
    "            if len(duplicate_indexes) > 0:\n",
    "                print(f\"File: {file_name} has {len(duplicate_indexes)} duplicate indexes.\")\n",
    "            # else:\n",
    "            #     print(f\"File: {file_name} has no duplicate indexes.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
