{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Yeast Master Matrix From Microarray Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Misc Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GWEIGHTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# List to store file names with non-uniform GWEIGHT values\n",
    "files_with_non_uniform_gweight = []\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if the 'GWEIGHT' column exists\n",
    "            if 'GWEIGHT' in df.columns:\n",
    "                # Check if all values in 'GWEIGHT' are equal to 1\n",
    "                if not (df['GWEIGHT'] == 1).all():\n",
    "                    files_with_non_uniform_gweight.append(file_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the results\n",
    "if files_with_non_uniform_gweight:\n",
    "    print(\"Files with non-uniform GWEIGHT values:\")\n",
    "    for file in files_with_non_uniform_gweight:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"All files have GWEIGHT values uniformly equal to 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Number of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Counter for total number of experiment columns\n",
    "total_experiment_columns = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Count the experiment columns (excluding 'GWEIGHT', 'NAME', 'IDENTIFIER', 'Description', etc.)\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME', 'IDENTIFIER', 'Description']]\n",
    "            total_experiment_columns += len(experiment_columns)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total number of experiment columns\n",
    "print(f\"Total number of experiment columns across all files: {total_experiment_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Files with More Genes than Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Threshold for the size of the yeast genome\n",
    "threshold = 7337\n",
    "\n",
    "# Counter for files with unique rows exceeding the threshold\n",
    "count_exceeding_files = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Find the number of unique rows\n",
    "            unique_count = df.drop_duplicates().shape[0]\n",
    "\n",
    "            # Check if the unique count exceeds the threshold\n",
    "            if unique_count > threshold:\n",
    "                count_exceeding_files += 1\n",
    "\n",
    "                # Count rows where the YORF (index) starts with 'SGD'\n",
    "                sgd_count = sum(df.index.astype(str).str.startswith('SGD'))\n",
    "\n",
    "                print(f\"File: {file_name}, Number of unique rows: {unique_count}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total count of files exceeding the threshold\n",
    "print(f\"Number of files with unique rows larger than {threshold}: {count_exceeding_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalizing Columns in Each .pcl File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Exclude non-experiment columns from normalization\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME']]\n",
    "\n",
    "            # Cast the experiment columns to float32\n",
    "            df[experiment_columns] = df[experiment_columns].astype('float32')\n",
    "\n",
    "            # Initialize the scaler\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "            # Apply z-score normalization for each experiment column\n",
    "            df[experiment_columns] = scaler.fit_transform(df[experiment_columns])\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Translating All Indexes to YORFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with SGD Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files and the all_yeast_genes.tsv file\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the all_yeast_genes.tsv to create the mapping dictionary\n",
    "genes_df = pd.read_csv(genes_file, sep='\\t')\n",
    "gene_mapping = dict(zip(genes_df['Gene > Primary DBID'], genes_df['Gene > Systematic Name']))\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Replace index values that start with 'SGD' using the mapping dictionary\n",
    "            df.index = df.index.to_series().apply(lambda x: gene_mapping.get(x, x) if x.startswith('SGD') else x)\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_checked = 0\n",
    "sgd_found = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if any index starts with 'SGD'\n",
    "            if df.index.str.startswith('SGD').any():\n",
    "                print(f\"Found 'SGD' in indices of file: {file_name}\")\n",
    "                sgd_found += 1\n",
    "\n",
    "            files_checked += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Checked {files_checked} files.\")\n",
    "print(f\"Found 'SGD' indices in {sgd_found} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with Standard Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes_v2.tsv' # Contains some manual additions\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create a dictionary mapping Gene > Standard Name to Gene > Systematic Name (case-insensitive)\n",
    "standard_to_systematic = {\n",
    "    standard.upper(): systematic.upper() \n",
    "    for standard, systematic in zip(\n",
    "        yeast_genes_df['Gene > Standard Name'].dropna(), \n",
    "        yeast_genes_df['Gene > Systematic Name'].dropna()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Flag to check if the file was modified\n",
    "            modified = False\n",
    "\n",
    "            # Create a new index list\n",
    "            new_index = []\n",
    "            for index in pcl_df.index:\n",
    "                # Check if the index is problematic (not in standard_to_systematic dictionary)\n",
    "                upper_index = index.upper()\n",
    "                if upper_index not in standard_to_systematic:\n",
    "                    # Keep the index as is if no mapping exists\n",
    "                    new_index.append(index)\n",
    "                else:\n",
    "                    # Replace the index with the corresponding Gene > Systematic Name\n",
    "                    new_index.append(standard_to_systematic[upper_index])\n",
    "                    modified = True\n",
    "\n",
    "            # Update the index of the DataFrame if modified\n",
    "            if modified:\n",
    "                pcl_df.index = new_index\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "\n",
    "                print(f\"File '{file_name}' updated successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with the Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YERWomega2: 19 occurrences\n",
      "YGRWTy2-2: 18 occurrences\n",
      "YLRCTy2-2: 18 occurrences\n",
      "YLRCTy1-1: 18 occurrences\n",
      "YMRCTy1-4: 18 occurrences\n",
      "YORCTy2-1: 18 occurrences\n",
      "YPLCTy4-1: 18 occurrences\n",
      "YPLWTy1-1: 18 occurrences\n",
      "YILWTy3-1: 18 occurrences\n",
      "YGRCTy1-3: 18 occurrences\n",
      "YBRWTy1-2: 18 occurrences\n",
      "YDRWTy1-5: 18 occurrences\n",
      "YFLWTy2-1: 18 occurrences\n",
      "YLRWTy1-3: 18 occurrences\n",
      "YOLWTy1-1: 18 occurrences\n",
      "YLRWTy1-2: 18 occurrences\n",
      "YGRWTy1-1: 18 occurrences\n",
      "YBLWTy1-1: 18 occurrences\n",
      "YPRWTy1-3: 18 occurrences\n",
      "YDRCTy1-3: 18 occurrences\n",
      "YJLWTy4-1: 18 occurrences\n",
      "YNLCTy2-1: 18 occurrences\n",
      "YJRWTy1-2: 18 occurrences\n",
      "YDRCTy1-1: 18 occurrences\n",
      "YPRCTy1-4: 18 occurrences\n",
      "YPRCTy1-2: 18 occurrences\n",
      "YMLWTy1-2: 18 occurrences\n",
      "YDRCTy2-1: 18 occurrences\n",
      "YARCTy1-1: 18 occurrences\n",
      "YDRWTy2-2: 18 occurrences\n",
      "YNLWTy1-2: 18 occurrences\n",
      "YNLCTy1-1: 18 occurrences\n",
      "YDRWTy1-4: 18 occurrences\n",
      "YGRCTy1-2: 18 occurrences\n",
      "YBLWTy2-1: 18 occurrences\n",
      "YORWTy2-2: 18 occurrences\n",
      "YCLWTy2-1: 18 occurrences\n",
      "YORWTy1-2: 18 occurrences\n",
      "YGRWTy3-1: 18 occurrences\n",
      "YDRWTy2-3: 18 occurrences\n",
      "YDRCTy1-2: 18 occurrences\n",
      "YJRWTy1-1: 18 occurrences\n",
      "YHRCTy1-1: 18 occurrences\n",
      "YMLWTy1-1: 18 occurrences\n",
      "YERCTy1-1: 18 occurrences\n",
      "YMRCTy1-3: 18 occurrences\n",
      "YLRWTy2-1: 18 occurrences\n",
      "YGRCTy2-1: 18 occurrences\n",
      "YHLComega1: 16 occurrences\n",
      "tE(CUC)D: 14 occurrences\n",
      "tD(GUC)J1: 14 occurrences\n",
      "tS(AGA)E: 14 occurrences\n",
      "tE(UUC)J: 14 occurrences\n",
      "tQ(UUG)E1: 14 occurrences\n",
      "tR(ACG)J: 14 occurrences\n",
      "tR(UCU)D: 14 occurrences\n",
      "tE(UUC)L: 14 occurrences\n",
      "tV(CAC)D: 14 occurrences\n",
      "tS(AGA)D1: 14 occurrences\n",
      "tR(UCU)B: 14 occurrences\n",
      "tQ(UUG)D2: 14 occurrences\n",
      "tQ(UUG)L: 14 occurrences\n",
      "tS(AGA)A: 14 occurrences\n",
      "tS(AGA)L: 14 occurrences\n",
      "tH(GUG)M: 14 occurrences\n",
      "tK(CUU)J: 14 occurrences\n",
      "tR(UCU)M2: 14 occurrences\n",
      "tN(GUU)C: 14 occurrences\n",
      "tR(UCU)J1: 14 occurrences\n",
      "tR(UCU)K: 14 occurrences\n",
      "tH(GUG)K: 14 occurrences\n",
      "tQ(UUG)C: 14 occurrences\n",
      "tS(AGA)D2: 14 occurrences\n",
      "tQ(UUG)E2: 14 occurrences\n",
      "tE(UUC)E1: 14 occurrences\n",
      "tS(UGA)P: 14 occurrences\n",
      "tE(UUC)K: 14 occurrences\n",
      "tQ(UUG)D1: 14 occurrences\n",
      "tE(UUC)M: 14 occurrences\n",
      "tE(UUC)B: 14 occurrences\n",
      "tH(GUG)E1: 14 occurrences\n",
      "tR(UCU)E: 14 occurrences\n",
      "tQ(UUG)D3: 14 occurrences\n",
      "tV(AAC)J: 14 occurrences\n",
      "tS(AGA)J: 14 occurrences\n",
      "CEN12: 14 occurrences\n",
      "tQ(UUG)B: 14 occurrences\n",
      "tE(UUC)P: 14 occurrences\n",
      "tE(UUC)C: 14 occurrences\n",
      "tS(AGA)M: 14 occurrences\n",
      "tC(GCA)P1: 14 occurrences\n",
      "tR(UCU)M1: 14 occurrences\n",
      "tS(AGA)B: 14 occurrences\n",
      "tR(UCU)J2: 14 occurrences\n",
      "tR(ACG)K: 13 occurrences\n",
      "tR(ACG)O: 13 occurrences\n",
      "tN(GUU)K: 13 occurrences\n",
      "tA(AGC)K2: 13 occurrences\n",
      "tR(ACG)L: 13 occurrences\n",
      "YCRWomega3: 13 occurrences\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes_rest_of_problematic_update.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create sets for faster lookups\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'])\n",
    "\n",
    "problematic_gene_counts = Counter()\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Find problematic indexes\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index\n",
    "                if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            # Print problematic file and indexes\n",
    "            if problematic_indexes and len(problematic_indexes) <= 5:\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "                print('-----------------------------------')\n",
    "\n",
    "            # Update the counter with the problematic indexes\n",
    "            problematic_gene_counts.update(problematic_indexes)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "for gene, count in problematic_gene_counts.most_common(100):\n",
    "    print(f\"{gene}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For now, let's remove the problematic index if YORF available and same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to directories and files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "gene_mapping_path = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the valid systematic names from the mapping file\n",
    "gene_mapping_df = pd.read_csv(gene_mapping_path, sep='\\t')\n",
    "valid_systematic_names = set(gene_mapping_df['Gene > Systematic Name'].dropna())\n",
    "\n",
    "# Process each .pcl file\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory), start=1):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify problematic indexes (not in valid systematic names)\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            if problematic_indexes:\n",
    "                print(f\"Processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "\n",
    "                # Check if problematic indexes have matching valid systematic name rows\n",
    "                rows_to_drop = []\n",
    "                for problem_index in problematic_indexes:\n",
    "                    # Check if there is a matching row with valid systematic name\n",
    "                    matching_rows = pcl_df.loc[\n",
    "                        pcl_df.index.isin(valid_systematic_names) & \n",
    "                        (pcl_df.loc[problem_index].drop(['NAME', 'GWEIGHT'], errors='ignore') == pcl_df.drop(['NAME', 'GWEIGHT'], axis=1, errors='ignore')).all(axis=1)\n",
    "                    ]\n",
    "\n",
    "                    # If a matching row exists, mark the problematic index for removal\n",
    "                    if not matching_rows.empty:\n",
    "                        rows_to_drop.append(problem_index)\n",
    "\n",
    "                # Remove the problematic rows and overwrite the file\n",
    "                if rows_to_drop:\n",
    "                    pcl_df = pcl_df.drop(index=rows_to_drop)\n",
    "                    pcl_df.to_csv(file_path, sep='\\t')\n",
    "                    print(f\"Fixed and overwritten file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                else:\n",
    "                    print(f\"No matching rows found for problematic indexes in file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Apparently, most of the remaining problematic genes are \"LTRs\". Remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to directories and files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Process each .pcl file\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory), start=1):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows to remove by checking if index contains 'delta', 'sigma', 'tau' or 'omega'\n",
    "            rows_to_remove = [\n",
    "                index for index in pcl_df.index if any(x in index.lower() for x in ['delta', 'sigma', 'tau', 'omega'])\n",
    "            ]\n",
    "\n",
    "            if rows_to_remove:\n",
    "                print(f\"Processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Rows to remove: {rows_to_remove}\")\n",
    "\n",
    "                # Remove the rows and overwrite the file\n",
    "                pcl_df = pcl_df.drop(index=rows_to_remove)\n",
    "                pcl_df.to_csv(file_path, sep='\\t')\n",
    "                print(f\"Fixed and overwritten file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "            else:\n",
    "                print(f\"No rows to remove in file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For simplicity, let's just discard the remaining since we would need to manually look up everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Get the set of valid systematic names, ensuring case insensitivity\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'].str.upper())\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows with indexes not in the valid systematic names\n",
    "            invalid_indexes = [index for index in pcl_df.index if index.upper() not in valid_systematic_names]\n",
    "\n",
    "            # If invalid rows are found, drop them\n",
    "            if invalid_indexes:\n",
    "                pcl_df.drop(index=invalid_indexes, inplace=True)\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "                print(f\"File '{file_name}' updated: Removed {len(invalid_indexes)} invalid rows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].unique()\n",
    "            \n",
    "            if len(duplicate_indexes) > 0:\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Number of duplicate indexes: {len(duplicate_indexes)}\")\n",
    "\n",
    "                # Check if the rows match for each duplicate index\n",
    "                for dup_index in duplicate_indexes:\n",
    "                    duplicate_rows = pcl_df.loc[dup_index]\n",
    "                    \n",
    "                    # Count occurrences of the duplicate index\n",
    "                    num_duplicates = len(duplicate_rows) if isinstance(duplicate_rows, pd.DataFrame) else 1\n",
    "                    \n",
    "                    # Handle duplicates with 3 or more occurrences\n",
    "                    if num_duplicates >= 3:\n",
    "                        print(f\"  - Gene '{dup_index}' has {num_duplicates} duplicates.\")\n",
    "                    \n",
    "                    # Check if the rows match\n",
    "                    if isinstance(duplicate_rows, pd.DataFrame):\n",
    "                        experiment_columns = duplicate_rows.drop(columns=['NAME', 'GWEIGHT'], errors='ignore')\n",
    "                        \n",
    "                        # Check if all rows are identical\n",
    "                        rows_match = experiment_columns.nunique().sum() == experiment_columns.shape[1]\n",
    "                        \n",
    "                        if rows_match:\n",
    "                            print(f\"    - Duplicate index '{dup_index}' has matching rows.\")\n",
    "                        else:\n",
    "                            print(f\"    - Duplicate index '{dup_index}' has non-matching rows.\")\n",
    "                    else:\n",
    "                        print(f\"  - Duplicate index '{dup_index}' has only one row (unexpected).\")\n",
    "\n",
    "                print('\\n')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing direct duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Drop duplicates based on the index and experimental columns (excluding NAME and GWEIGHT)\n",
    "            experimental_columns = pcl_df.drop(columns=['NAME', 'GWEIGHT'], errors='ignore')\n",
    "            deduplicated_df = pcl_df.loc[~experimental_columns.index.duplicated(keep='first')]\n",
    "\n",
    "            # Save the deduplicated DataFrame back to the same file\n",
    "            deduplicated_df.to_csv(pcl_file_path, sep='\\t')\n",
    "            print(f\"Duplicates removed for file: {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].unique()\n",
    "            \n",
    "            # Print if the file has duplicates or not\n",
    "            if len(duplicate_indexes) > 0:\n",
    "                print(f\"File: {file_name} has {len(duplicate_indexes)} duplicate indexes.\")\n",
    "            # else:\n",
    "            #     print(f\"File: {file_name} has no duplicate indexes.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
