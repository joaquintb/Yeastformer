{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Yeast Master Matrix From Microarray Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Misc Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GWEIGHTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# List to store file names with non-uniform GWEIGHT values\n",
    "files_with_non_uniform_gweight = []\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if the 'GWEIGHT' column exists\n",
    "            if 'GWEIGHT' in df.columns:\n",
    "                # Check if all values in 'GWEIGHT' are equal to 1\n",
    "                if not (df['GWEIGHT'] == 1).all():\n",
    "                    files_with_non_uniform_gweight.append(file_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the results\n",
    "if files_with_non_uniform_gweight:\n",
    "    print(\"Files with non-uniform GWEIGHT values:\")\n",
    "    for file in files_with_non_uniform_gweight:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"All files have GWEIGHT values uniformly equal to 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Number of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Counter for total number of experiment columns\n",
    "total_experiment_columns = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Count the experiment columns (excluding 'GWEIGHT', 'NAME', 'IDENTIFIER', 'Description', etc.)\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME', 'IDENTIFIER', 'Description']]\n",
    "            total_experiment_columns += len(experiment_columns)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total number of experiment columns\n",
    "print(f\"Total number of experiment columns across all files: {total_experiment_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Files with More Genes than Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Threshold for the size of the yeast genome\n",
    "threshold = 7337\n",
    "\n",
    "# Counter for files with unique rows exceeding the threshold\n",
    "count_exceeding_files = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Find the number of unique rows\n",
    "            unique_count = df.drop_duplicates().shape[0]\n",
    "\n",
    "            # Check if the unique count exceeds the threshold\n",
    "            if unique_count > threshold:\n",
    "                count_exceeding_files += 1\n",
    "\n",
    "                # Count rows where the YORF (index) starts with 'SGD'\n",
    "                sgd_count = sum(df.index.astype(str).str.startswith('SGD'))\n",
    "\n",
    "                print(f\"File: {file_name}, Number of unique rows: {unique_count}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total count of files exceeding the threshold\n",
    "print(f\"Number of files with unique rows larger than {threshold}: {count_exceeding_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalizing Columns in Each .pcl File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Exclude non-experiment columns from normalization\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME']]\n",
    "\n",
    "            # Cast the experiment columns to float32\n",
    "            df[experiment_columns] = df[experiment_columns].astype('float32')\n",
    "\n",
    "            # Initialize the scaler\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "            # Apply z-score normalization for each experiment column\n",
    "            df[experiment_columns] = scaler.fit_transform(df[experiment_columns])\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Translating All Indexes to YORFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with SGD Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 556 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files and the all_yeast_genes.tsv file\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the all_yeast_genes.tsv to create the mapping dictionary\n",
    "genes_df = pd.read_csv(genes_file, sep='\\t')\n",
    "gene_mapping = dict(zip(genes_df['Gene > Primary DBID'], genes_df['Gene > Systematic Name']))\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Replace index values that start with 'SGD' using the mapping dictionary\n",
    "            df.index = df.index.to_series().apply(lambda x: gene_mapping.get(x, x) if x.startswith('SGD') else x)\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checked 556 files.\n",
      "Found 'SGD' indices in 0 files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_checked = 0\n",
    "sgd_found = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if any index starts with 'SGD'\n",
    "            if df.index.str.startswith('SGD').any():\n",
    "                print(f\"Found 'SGD' in indices of file: {file_name}\")\n",
    "                sgd_found += 1\n",
    "\n",
    "            files_checked += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Checked {files_checked} files.\")\n",
    "print(f\"Found 'SGD' indices in {sgd_found} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with Standard Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'GSE24802_final.pcl' updated successfully.\n",
      "File 'GSE66521.mapped.pcl' updated successfully.\n",
      "File 'GSE25081_final.pcl' updated successfully.\n",
      "File 'GSE30168_final.pcl' updated successfully.\n",
      "File 'GSE54539.remapped.final.pcl' updated successfully.\n",
      "File 'GSE33427.remapped.final.pcl' updated successfully.\n",
      "File 'GSE55223.final.pcl' updated successfully.\n",
      "File 'GSE22832_final.pcl' updated successfully.\n",
      "File 'GSE44871.remapped.final.pcl' updated successfully.\n",
      "File 'GSE44085.remapped.final.pcl' updated successfully.\n",
      "File 'GSE63663.final.pcl' updated successfully.\n",
      "File 'GSE27234_final.pcl' updated successfully.\n",
      "File '2010.Bulik03.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE89875.mapped.pcl' updated successfully.\n",
      "File 'GSE49340.remapped.final.pcl' updated successfully.\n",
      "File 'GSE81480.mapped.pcl' updated successfully.\n",
      "File 'GSE40351.remapped.final.pcl' updated successfully.\n",
      "File '2010.Bro03.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File '2010.Martin04.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE54844.final.pcl' updated successfully.\n",
      "File 'GSE32196GPL15778.sfp.pcl' updated successfully.\n",
      "File 'GSE33844_final.pcl' updated successfully.\n",
      "File 'GSE39419_final.pcl' updated successfully.\n",
      "File 'GSE94945.mapped.pcl' updated successfully.\n",
      "File 'GSE48956.remapped.final.pcl' updated successfully.\n",
      "File 'GSE81479.mapped.pcl' updated successfully.\n",
      "File 'GSE76985.mapped.pcl' updated successfully.\n",
      "File 'GSE39311.remapped.final.pcl' updated successfully.\n",
      "File 'GSE63187.final.pcl' updated successfully.\n",
      "File 'GSE27062_final.pcl' updated successfully.\n",
      "File 'GSE59659.final.pcl' updated successfully.\n",
      "File 'GSE30148_final.pcl' updated successfully.\n",
      "File 'GSE80748.mapped.pcl' updated successfully.\n",
      "File 'GSE26437_final.pcl' updated successfully.\n",
      "File '2010.Orlandi04.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE54851.final.pcl' updated successfully.\n",
      "File 'GSE31389_final.pcl' updated successfully.\n",
      "File 'GSE26923_final.pcl' updated successfully.\n",
      "File 'GSE24681_final.pcl' updated successfully.\n",
      "File 'GSE47429.remapped.final.pcl' updated successfully.\n",
      "File 'GSE45692.remapped.final.pcl' updated successfully.\n",
      "File 'GSE29420_final.pcl' updated successfully.\n",
      "File 'GSE39861.remapped.final.pcl' updated successfully.\n",
      "File 'GSE55081.remapped.final.pcl' updated successfully.\n",
      "File 'GSE36118_final.pcl' updated successfully.\n",
      "File 'GSE34787_final.pcl' updated successfully.\n",
      "File 'GSE34330GPL8154.sfp.pcl' updated successfully.\n",
      "File 'GSE41025.remapped.final.pcl' updated successfully.\n",
      "File '2010.Bernstein00_TSA.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE40073_final.pcl' updated successfully.\n",
      "File 'GSE33185_final.pcl' updated successfully.\n",
      "File '2010.Bernstein00_HDACsin3sap30ume6hda1hos2hos3.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE54850.final.pcl' updated successfully.\n",
      "File 'GSE42536.mapped.pcl' updated successfully.\n",
      "File 'GSE33097_s257_final.pcl' updated successfully.\n",
      "File 'GSE62399.final.pcl' updated successfully.\n",
      "File 'GSE38848.remapped.final.pcl' updated successfully.\n",
      "File 'GSE24712_final.pcl' updated successfully.\n",
      "File 'GSE29371_final.pcl' updated successfully.\n",
      "File 'GSE96849.mapped.pcl' updated successfully.\n",
      "File 'GSE51563.remapped.final.pcl' updated successfully.\n",
      "File 'GSE65225.mapped.pcl' updated successfully.\n",
      "File 'GSE54527.remapped.final.pcl' updated successfully.\n",
      "File 'GSE39950.remapped.final.pcl' updated successfully.\n",
      "File 'GSE28677_final.pcl' updated successfully.\n",
      "File '2010.Boer05.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE31326_final.pcl' updated successfully.\n",
      "File 'GSE45776.remapped.final.pcl' updated successfully.\n",
      "File 'GSE68816.mapped.pcl' updated successfully.\n",
      "File 'GSE23580_final.pcl' updated successfully.\n",
      "File 'GSE26829_final.pcl' updated successfully.\n",
      "File 'GSE45273.remapped.final.pcl' updated successfully.\n",
      "File 'GSE18994_final.pcl' updated successfully.\n",
      "File 'GSE17716_final.pcl' updated successfully.\n",
      "File 'GSE40817_final.pcl' updated successfully.\n",
      "File 'GSE36958_final.pcl' updated successfully.\n",
      "File 'GSE39903.remapped.final.pcl' updated successfully.\n",
      "File 'GSE36599.remapped.final.pcl' updated successfully.\n",
      "File 'GSE27222_final.pcl' updated successfully.\n",
      "File 'GSE41094.remapped.final.pcl' updated successfully.\n",
      "File 'GSE75447.mapped.pcl' updated successfully.\n",
      "File 'GSE21571_final.pcl' updated successfully.\n",
      "File 'GSE50947.remapped.final.pcl' updated successfully.\n",
      "File 'GSE43120.remapped.final.pcl' updated successfully.\n",
      "File '2010.Rudra05.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE34757_final.pcl' updated successfully.\n",
      "File '2010.Schawalder04.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE35853_final.pcl' updated successfully.\n",
      "File 'GSE34117.remapped.final.pcl' updated successfully.\n",
      "File 'GSE50440.remapped.final.pcl' updated successfully.\n",
      "File 'GSE103392.mapped.pcl' updated successfully.\n",
      "File 'GSE40116.remapped.final.pcl' updated successfully.\n",
      "File 'GSE32703_final.pcl' updated successfully.\n",
      "File 'GSE47820.remapped.final.pcl' updated successfully.\n",
      "File 'GSE33929.remapped.final.pcl' updated successfully.\n",
      "File 'GSE27185_final.pcl' updated successfully.\n",
      "File 'GSE47712.remapped.final.pcl' updated successfully.\n",
      "File 'GSE62400.mapped.pcl' updated successfully.\n",
      "File 'GSE45370.remapped.final.pcl' updated successfully.\n",
      "File 'GSE67428.final.pcl' updated successfully.\n",
      "File 'GSE40254.remapped.final.pcl' updated successfully.\n",
      "File 'GSE31176_final.pcl' updated successfully.\n",
      "File 'GSE64468.final.pcl' updated successfully.\n",
      "File 'GSE24675_final.pcl' updated successfully.\n",
      "File 'GSE38653.final.pcl' updated successfully.\n",
      "File 'GSE18334_final.pcl' updated successfully.\n",
      "File '2010.Fry03.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE65283.mapped.pcl' updated successfully.\n",
      "File 'GSE36955.remapped.final.pcl' updated successfully.\n",
      "File 'GSE33098_final.pcl' updated successfully.\n",
      "File 'GSE40116_final.pcl' updated successfully.\n",
      "File 'GSE31390_final.pcl' updated successfully.\n",
      "File '2010.Sabet04.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE29960_final.pcl' updated successfully.\n",
      "File 'GSE54340.remapped.final.pcl' updated successfully.\n",
      "File 'GSE36954.remapped.final.pcl' updated successfully.\n",
      "File 'GSE50186.remapped.final.pcl' updated successfully.\n",
      "File 'GSE54528.remapped.final.pcl' updated successfully.\n",
      "File '2010.Pitkanen04.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE26303_final.pcl' updated successfully.\n",
      "File 'GSE25909_s313_final.pcl' updated successfully.\n",
      "File 'GSE22122_final.pcl' updated successfully.\n",
      "File 'GSE63030.final.pcl' updated successfully.\n",
      "File 'GSE27925_final.pcl' updated successfully.\n",
      "File 'GSE65666.final.pcl' updated successfully.\n",
      "File 'GSE32974_final.pcl' updated successfully.\n",
      "File 'GSE32418_final.pcl' updated successfully.\n",
      "File 'GSE19302_final.pcl' updated successfully.\n",
      "File 'GSE23711_final.pcl' updated successfully.\n",
      "File '2010.Jin04.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE30046_final.pcl' updated successfully.\n",
      "File 'GSE68487.mapped.pcl' updated successfully.\n",
      "File 'GSE62161.mapped.pcl' updated successfully.\n",
      "File 'GSE38260.remapped.final.pcl' updated successfully.\n",
      "File 'GSE31774_final.pcl' updated successfully.\n",
      "File 'GSE34286_final.pcl' updated successfully.\n",
      "File 'GSE42027.remapped.final.pcl' updated successfully.\n",
      "File 'GSE33695_final.pcl' updated successfully.\n",
      "File '2010.Tai05.filter.flt.knn.avg.div.log.pcl' updated successfully.\n",
      "File 'GSE24421_final.pcl' updated successfully.\n",
      "File 'GSE25697_final.pcl' updated successfully.\n",
      "File 'GSE66176.final.pcl' updated successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes_v2.tsv' # Contains some manual additions\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create a dictionary mapping Gene > Standard Name to Gene > Systematic Name (case-insensitive)\n",
    "standard_to_systematic = {\n",
    "    standard.upper(): systematic.upper() \n",
    "    for standard, systematic in zip(\n",
    "        yeast_genes_df['Gene > Standard Name'].dropna(), \n",
    "        yeast_genes_df['Gene > Systematic Name'].dropna()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Flag to check if the file was modified\n",
    "            modified = False\n",
    "\n",
    "            # Create a new index list\n",
    "            new_index = []\n",
    "            for index in pcl_df.index:\n",
    "                # Check if the index is problematic (not in standard_to_systematic dictionary)\n",
    "                upper_index = index.upper()\n",
    "                if upper_index not in standard_to_systematic:\n",
    "                    # Keep the index as is if no mapping exists\n",
    "                    new_index.append(index)\n",
    "                else:\n",
    "                    # Replace the index with the corresponding Gene > Systematic Name\n",
    "                    new_index.append(standard_to_systematic[upper_index])\n",
    "                    modified = True\n",
    "\n",
    "            # Update the index of the DataFrame if modified\n",
    "            if modified:\n",
    "                pcl_df.index = new_index\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "\n",
    "                print(f\"File '{file_name}' updated successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are close to the size of the genome, but still having some extra rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create sets for faster lookups\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'])\n",
    "\n",
    "all_problematic_genes = set()\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Find problematic indexes\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index\n",
    "                if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            # Print problematic file and indexes\n",
    "            if problematic_indexes:\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "                all_problematic_genes.update(problematic_indexes)\n",
    "                print('-----------------------------------')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(len(all_problematic_genes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For simplicity, let's just discard the remaining since we would need to manually look up everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Get the set of valid systematic names, ensuring case insensitivity\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'].str.upper())\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows with indexes not in the valid systematic names\n",
    "            invalid_indexes = [index for index in pcl_df.index if index.upper() not in valid_systematic_names]\n",
    "\n",
    "            # If invalid rows are found, drop them\n",
    "            if invalid_indexes:\n",
    "                pcl_df.drop(index=invalid_indexes, inplace=True)\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "                print(f\"File '{file_name}' updated: Removed {len(invalid_indexes)} invalid rows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problem: if not treated, master matrix would have two different names for the same gene and the matrix will grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the normalized folder\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Initialize a flag to indicate whether the index is found\n",
    "found = False\n",
    "\n",
    "# Process each .pcl file in the folder\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if 'YJR084W' exists as an index\n",
    "            if 'YJR084W' in pcl_df.index:\n",
    "                print(f\"Found 'YJR084W' in file: {file_name}\")\n",
    "                found = True\n",
    "                break  # Stop the loop as the index is found\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# If not found in any file, notify\n",
    "if not found:\n",
    "    print(\"'YJR084W' not found in any file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's look for repeated YORF rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the normalized folder\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Flag to stop processing if a problematic file is found\n",
    "problem_found = False\n",
    "\n",
    "# Process each .pcl file in the folder\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check for duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].tolist()\n",
    "            if duplicate_indexes:\n",
    "                print(f\"Problematic file: {file_name}\")\n",
    "                print(f\"Duplicate indexes: {duplicate_indexes}\")\n",
    "                # problem_found = True\n",
    "                # break  # Stop the loop at the first problematic file\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# If no problematic file is found, notify\n",
    "if not problem_found:\n",
    "    print(\"All files have unique row indexes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Apparently again rows are repeated, the corresponding YORF contains the same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Extract valid Gene > Systematic Names\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'])\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory)):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify problematic indexes\n",
    "            problematic_indexes = [index for index in pcl_df.index if index not in valid_systematic_names]\n",
    "\n",
    "            # Store problematic genes that fail the condition\n",
    "            unsatisfied_genes = []\n",
    "\n",
    "            # Iterate over problematic indexes\n",
    "            for problematic_index in problematic_indexes:\n",
    "                # Get experimental data for the problematic row, excluding NAME and GWEIGHT\n",
    "                problematic_data = pcl_df.loc[problematic_index].drop(['NAME', 'GWEIGHT'], errors='ignore')\n",
    "\n",
    "                # Check for matching rows with indexes starting with 'Y'\n",
    "                matching_rows = pcl_df[\n",
    "                    pcl_df.index.str.startswith('Y')\n",
    "                    & (pcl_df.drop(columns=['NAME', 'GWEIGHT'], errors='ignore') == problematic_data).all(axis=1)\n",
    "                ]\n",
    "\n",
    "                # If no matching row is found, add to unsatisfied list\n",
    "                if matching_rows.empty:\n",
    "                    unsatisfied_genes.append(problematic_index)\n",
    "\n",
    "            # If there are unsatisfied genes, print the file and the genes\n",
    "            if unsatisfied_genes:\n",
    "                print(f\"File ({file_count +1}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Problematic genes without matching 'Y' rows: {len(unsatisfied_genes)}\")\n",
    "                print('\\n')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For now, let's remove the problematic index if YORF available and same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to directories and files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "gene_mapping_path = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the valid systematic names from the mapping file\n",
    "gene_mapping_df = pd.read_csv(gene_mapping_path, sep='\\t')\n",
    "valid_systematic_names = set(gene_mapping_df['Gene > Systematic Name'].dropna())\n",
    "\n",
    "# Process each .pcl file\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory), start=1):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify problematic indexes (not in valid systematic names)\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            if problematic_indexes:\n",
    "                print(f\"Processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "\n",
    "                # Check if problematic indexes have matching valid systematic name rows\n",
    "                rows_to_drop = []\n",
    "                for problem_index in problematic_indexes:\n",
    "                    # Check if there is a matching row with valid systematic name\n",
    "                    matching_rows = pcl_df.loc[\n",
    "                        pcl_df.index.isin(valid_systematic_names) & \n",
    "                        (pcl_df.loc[problem_index].drop(['NAME', 'GWEIGHT'], errors='ignore') == pcl_df.drop(['NAME', 'GWEIGHT'], axis=1, errors='ignore')).all(axis=1)\n",
    "                    ]\n",
    "\n",
    "                    # If a matching row exists, mark the problematic index for removal\n",
    "                    if not matching_rows.empty:\n",
    "                        rows_to_drop.append(problem_index)\n",
    "\n",
    "                # Remove the problematic rows and overwrite the file\n",
    "                if rows_to_drop:\n",
    "                    pcl_df = pcl_df.drop(index=rows_to_drop)\n",
    "                    pcl_df.to_csv(file_path, sep='\\t')\n",
    "                    print(f\"Fixed and overwritten file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                else:\n",
    "                    print(f\"No matching rows found for problematic indexes in file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].unique()\n",
    "            \n",
    "            if len(duplicate_indexes) > 0:\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Number of duplicate indexes: {len(duplicate_indexes)}\")\n",
    "\n",
    "                # Check if the rows match for each duplicate index\n",
    "                for dup_index in duplicate_indexes:\n",
    "                    duplicate_rows = pcl_df.loc[dup_index]\n",
    "                    \n",
    "                    # Count occurrences of the duplicate index\n",
    "                    num_duplicates = len(duplicate_rows) if isinstance(duplicate_rows, pd.DataFrame) else 1\n",
    "                    \n",
    "                    # Handle duplicates with 3 or more occurrences\n",
    "                    if num_duplicates >= 3:\n",
    "                        print(f\"  - Gene '{dup_index}' has {num_duplicates} duplicates.\")\n",
    "                    \n",
    "                    # Check if the rows match\n",
    "                    if isinstance(duplicate_rows, pd.DataFrame):\n",
    "                        experiment_columns = duplicate_rows.drop(columns=['NAME', 'GWEIGHT'], errors='ignore')\n",
    "                        \n",
    "                        # Check if all rows are identical\n",
    "                        rows_match = experiment_columns.nunique().sum() == experiment_columns.shape[1]\n",
    "                        \n",
    "                        if rows_match:\n",
    "                            print(f\"    - Duplicate index '{dup_index}' has matching rows.\")\n",
    "                        else:\n",
    "                            print(f\"    - Duplicate index '{dup_index}' has non-matching rows.\")\n",
    "                    else:\n",
    "                        print(f\"  - Duplicate index '{dup_index}' has only one row (unexpected).\")\n",
    "\n",
    "                print('\\n')\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing direct duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Drop duplicates based on the index and experimental columns (excluding NAME and GWEIGHT)\n",
    "            experimental_columns = pcl_df.drop(columns=['NAME', 'GWEIGHT'], errors='ignore')\n",
    "            deduplicated_df = pcl_df.loc[~experimental_columns.index.duplicated(keep='first')]\n",
    "\n",
    "            # Save the deduplicated DataFrame back to the same file\n",
    "            deduplicated_df.to_csv(pcl_file_path, sep='\\t')\n",
    "            print(f\"Duplicates removed for file: {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].unique()\n",
    "            \n",
    "            # Print if the file has duplicates or not\n",
    "            if len(duplicate_indexes) > 0:\n",
    "                print(f\"File: {file_name} has {len(duplicate_indexes)} duplicate indexes.\")\n",
    "            # else:\n",
    "            #     print(f\"File: {file_name} has no duplicate indexes.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
