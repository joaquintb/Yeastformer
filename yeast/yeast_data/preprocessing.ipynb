{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Yeast Matrix From Microarray Expression Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Misc Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GWEIGHTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# List to store file names with non-uniform GWEIGHT values\n",
    "files_with_non_uniform_gweight = []\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if the 'GWEIGHT' column exists\n",
    "            if 'GWEIGHT' in df.columns:\n",
    "                # Check if all values in 'GWEIGHT' are equal to 1\n",
    "                if not (df['GWEIGHT'] == 1).all():\n",
    "                    files_with_non_uniform_gweight.append(file_name)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the results\n",
    "if files_with_non_uniform_gweight:\n",
    "    print(\"Files with non-uniform GWEIGHT values:\")\n",
    "    for file in files_with_non_uniform_gweight:\n",
    "        print(file)\n",
    "else:\n",
    "    print(\"All files have GWEIGHT values uniformly equal to 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Number of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Counter for total number of experiment columns\n",
    "total_experiment_columns = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Count the experiment columns (excluding 'GWEIGHT', 'NAME', 'IDENTIFIER', 'Description', etc.)\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME', 'IDENTIFIER', 'Description']]\n",
    "            total_experiment_columns += len(experiment_columns)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total number of experiment columns\n",
    "print(f\"Total number of experiment columns across all files: {total_experiment_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Files with More Genes than Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Threshold for the size of the yeast genome\n",
    "threshold = 7337\n",
    "\n",
    "# Counter for files with unique rows exceeding the threshold\n",
    "count_exceeding_files = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Find the number of unique rows\n",
    "            unique_count = df.drop_duplicates().shape[0]\n",
    "\n",
    "            # Check if the unique count exceeds the threshold\n",
    "            if unique_count > threshold:\n",
    "                count_exceeding_files += 1\n",
    "\n",
    "                # Count rows where the YORF (index) starts with 'SGD'\n",
    "                sgd_count = sum(df.index.astype(str).str.startswith('SGD'))\n",
    "\n",
    "                print(f\"File: {file_name}, Number of unique rows: {unique_count}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Print the total count of files exceeding the threshold\n",
    "print(f\"Number of files with unique rows larger than {threshold}: {count_exceeding_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalizing Columns in Each .pcl File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Exclude non-experiment columns from normalization\n",
    "            experiment_columns = [col for col in df.columns if col not in ['GWEIGHT', 'NAME']]\n",
    "\n",
    "            # Cast the experiment columns to float32\n",
    "            df[experiment_columns] = df[experiment_columns].astype('float32')\n",
    "\n",
    "            # Initialize the scaler\n",
    "            scaler = StandardScaler()\n",
    "\n",
    "            # Apply z-score normalization for each experiment column\n",
    "            df[experiment_columns] = scaler.fit_transform(df[experiment_columns])\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Translating All Indexes to YORFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with SGD Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files and the all_yeast_genes.tsv file\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the all_yeast_genes.tsv to create the mapping dictionary\n",
    "genes_df = pd.read_csv(genes_file, sep='\\t')\n",
    "gene_mapping = dict(zip(genes_df['Gene > Primary DBID'], genes_df['Gene > Systematic Name']))\n",
    "\n",
    "files_processed = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Replace index values that start with 'SGD' using the mapping dictionary\n",
    "            df.index = df.index.to_series().apply(lambda x: gene_mapping.get(x, x) if x.startswith('SGD') else x)\n",
    "\n",
    "            # Save the modified DataFrame back to the same file\n",
    "            df.to_csv(file_path, sep=\"\\t\")\n",
    "\n",
    "            files_processed += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Processed {files_processed} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing .pcl files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "files_checked = 0\n",
    "sgd_found = 0\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the .pcl file\n",
    "            df = pd.read_csv(file_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "            # Check if any index starts with 'SGD'\n",
    "            if df.index.str.startswith('SGD').any():\n",
    "                print(f\"Found 'SGD' in indices of file: {file_name}\")\n",
    "                sgd_found += 1\n",
    "\n",
    "            files_checked += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "print(f\"Checked {files_checked} files.\")\n",
    "print(f\"Found 'SGD' indices in {sgd_found} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with Standard Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes_rest_of_problematic_update.tsv' # Contains some manual additions\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create a dictionary mapping Gene > Standard Name to Gene > Systematic Name (case-insensitive)\n",
    "standard_to_systematic = {\n",
    "    standard.upper(): systematic.upper() \n",
    "    for standard, systematic in zip(\n",
    "        yeast_genes_df['Gene > Standard Name'].dropna(), \n",
    "        yeast_genes_df['Gene > Systematic Name'].dropna()\n",
    "    )\n",
    "}\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Flag to check if the file was modified\n",
    "            modified = False\n",
    "\n",
    "            # Create a new index list\n",
    "            new_index = []\n",
    "            for index in pcl_df.index:\n",
    "                # Check if the index is problematic (not in standard_to_systematic dictionary)\n",
    "                upper_index = index.upper()\n",
    "                if upper_index not in standard_to_systematic:\n",
    "                    # Keep the index as is if no mapping exists\n",
    "                    new_index.append(index)\n",
    "                else:\n",
    "                    # Replace the index with the corresponding Gene > Systematic Name\n",
    "                    new_index.append(standard_to_systematic[upper_index])\n",
    "                    modified = True\n",
    "\n",
    "            # Update the index of the DataFrame if modified\n",
    "            if modified:\n",
    "                pcl_df.index = new_index\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "\n",
    "                print(f\"File '{file_name}' updated successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dealing with the Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes_rest_of_problematic_update.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Create sets for faster lookups\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'])\n",
    "\n",
    "problematic_gene_counts = Counter()\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Find problematic indexes\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index\n",
    "                if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            # Print problematic file and indexes\n",
    "            # if problematic_indexes:\n",
    "                # print(f\"File: {file_name}\")\n",
    "                # print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "                # print('-----------------------------------')\n",
    "\n",
    "            # Update the counter with the problematic indexes\n",
    "            problematic_gene_counts.update(problematic_indexes)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n",
    "\n",
    "# Iterate over all genes, not just the top 100, and filter those with count < 10\n",
    "for gene, count in problematic_gene_counts.items():\n",
    "    if count < 10 and count >=5 :\n",
    "        print(f\"{gene}: {count} occurrences\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### For now, let's remove the problematic index if YORF available and same values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to directories and files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "gene_mapping_path = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the valid systematic names from the mapping file\n",
    "gene_mapping_df = pd.read_csv(gene_mapping_path, sep='\\t')\n",
    "valid_systematic_names = set(gene_mapping_df['Gene > Systematic Name'].dropna())\n",
    "\n",
    "# Process each .pcl file\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory), start=1):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify problematic indexes (not in valid systematic names)\n",
    "            problematic_indexes = [\n",
    "                index for index in pcl_df.index if index not in valid_systematic_names\n",
    "            ]\n",
    "\n",
    "            if problematic_indexes:\n",
    "                print(f\"Processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Problematic indexes: {problematic_indexes}\")\n",
    "\n",
    "                # Check if problematic indexes have matching valid systematic name rows\n",
    "                rows_to_drop = []\n",
    "                for problem_index in problematic_indexes:\n",
    "                    # Check if there is a matching row with valid systematic name\n",
    "                    matching_rows = pcl_df.loc[\n",
    "                        pcl_df.index.isin(valid_systematic_names) & \n",
    "                        (pcl_df.loc[problem_index].drop(['NAME', 'GWEIGHT'], errors='ignore') == pcl_df.drop(['NAME', 'GWEIGHT'], axis=1, errors='ignore')).all(axis=1)\n",
    "                    ]\n",
    "\n",
    "                    # If a matching row exists, mark the problematic index for removal\n",
    "                    if not matching_rows.empty:\n",
    "                        rows_to_drop.append(problem_index)\n",
    "\n",
    "                # Remove the problematic rows and overwrite the file\n",
    "                if rows_to_drop:\n",
    "                    pcl_df = pcl_df.drop(index=rows_to_drop)\n",
    "                    pcl_df.to_csv(file_path, sep='\\t')\n",
    "                    print(f\"Fixed and overwritten file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                else:\n",
    "                    print(f\"No matching rows found for problematic indexes in file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Apparently, most of the remaining problematic genes are \"LTRs\". Remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to directories and files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Process each .pcl file\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory), start=1):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows to remove by checking if index contains 'delta', 'sigma', 'tau' or 'omega'\n",
    "            rows_to_remove = [\n",
    "                index for index in pcl_df.index if any(x in index.lower() for x in ['delta', 'sigma', 'tau', 'omega'])\n",
    "            ]\n",
    "\n",
    "            if rows_to_remove:\n",
    "                print(f\"Processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Rows to remove: {rows_to_remove}\")\n",
    "\n",
    "                # Remove the rows and overwrite the file\n",
    "                pcl_df = pcl_df.drop(index=rows_to_remove)\n",
    "                pcl_df.to_csv(file_path, sep='\\t')\n",
    "                print(f\"Fixed and overwritten file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "            else:\n",
    "                print(f\"No rows to remove in file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Removing more Retrotransposons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to directories and files\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# List of gene names to remove\n",
    "genes_to_remove = [\n",
    "    \"YGRWTy2-2\", \"YLRCTy2-2\", \"YLRCTy1-1\", \"YMRCTy1-4\", \"YORCTy2-1\", \"YPLCTy4-1\", \"YPLWTy1-1\",\n",
    "    \"YILWTy3-1\", \"YGRCTy1-3\", \"YBRWTy1-2\", \"YDRWTy1-5\", \"YFLWTy2-1\", \"YLRWTy1-3\", \"YOLWTy1-1\",\n",
    "    \"YLRWTy1-2\", \"YGRWTy1-1\", \"YBLWTy1-1\", \"YPRWTy1-3\", \"YDRCTy1-3\", \"YJLWTy4-1\", \"YNLCTy2-1\",\n",
    "    \"YJRWTy1-2\", \"YDRCTy1-1\", \"YPRCTy1-4\", \"YPRCTy1-2\", \"YMLWTy1-2\", \"YDRCTy2-1\", \"YARCTy1-1\",\n",
    "    \"YDRWTy2-2\", \"YNLWTy1-2\", \"YNLCTy1-1\", \"YDRWTy1-4\", \"YGRCTy1-2\", \"YBLWTy2-1\", \"YORWTy2-2\",\n",
    "    \"YCLWTy2-1\", \"YORWTy1-2\", \"YGRWTy3-1\", \"YDRWTy2-3\", \"YDRCTy1-2\", \"YJRWTy1-1\", \"YHRCTy1-1\",\n",
    "    \"YMLWTy1-1\", \"YERCTy1-1\", \"YMRCTy1-3\", \"YLRWTy2-1\", \"YGRCTy2-1\", \"YCLWTy5-1'\"\n",
    "]\n",
    "\n",
    "# Process each .pcl file\n",
    "for file_count, file_name in enumerate(os.listdir(pcl_directory), start=1):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows to remove by checking if index is in the list of genes to remove\n",
    "            rows_to_remove = [\n",
    "                index for index in pcl_df.index if index in genes_to_remove\n",
    "            ]\n",
    "\n",
    "            if rows_to_remove:\n",
    "                print(f\"Processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "                print(f\"Rows to remove: {rows_to_remove}\")\n",
    "\n",
    "                # Remove the rows and overwrite the file\n",
    "                pcl_df = pcl_df.drop(index=rows_to_remove)\n",
    "                pcl_df.to_csv(file_path, sep='\\t')\n",
    "                print(f\"Fixed and overwritten file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "            else:\n",
    "                print(f\"No rows to remove in file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file ({file_count}/{len(os.listdir(pcl_directory))}): {file_name}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Remove the remaining ones, which seem irrelevant and not a sig number of occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Get the set of valid systematic names, ensuring case insensitivity\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'].str.upper())\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows with indexes not in the valid systematic names\n",
    "            invalid_indexes = [index for index in pcl_df.index if index.upper() not in valid_systematic_names]\n",
    "\n",
    "            # If invalid rows are found, drop them\n",
    "            if invalid_indexes:\n",
    "                pcl_df.drop(index=invalid_indexes, inplace=True)\n",
    "\n",
    "                # Overwrite the original file\n",
    "                pcl_df.to_csv(pcl_file_path, sep='\\t')\n",
    "                print(f\"File '{file_name}' updated: Removed {len(invalid_indexes)} invalid rows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "yeast_genes_file = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_yeast_genes.tsv'\n",
    "\n",
    "# Load the yeast genes data\n",
    "yeast_genes_df = pd.read_csv(yeast_genes_file, sep='\\t')\n",
    "\n",
    "# Get the set of valid systematic names, ensuring case insensitivity\n",
    "valid_systematic_names = set(yeast_genes_df['Gene > Systematic Name'].str.upper())\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Identify rows with indexes not in the valid systematic names\n",
    "            invalid_indexes = [index for index in pcl_df.index if index.upper() not in valid_systematic_names]\n",
    "\n",
    "            # If invalid rows are found, report them\n",
    "            if invalid_indexes:\n",
    "                print(f\"File '{file_name}' has {len(invalid_indexes)} invalid rows: {', '.join(invalid_indexes)}.\")\n",
    "            # else:\n",
    "            #     print(f\"File '{file_name}' has all valid rows.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Dealing with Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify duplicate indexes\n",
    "            duplicate_indexes = pcl_df.index[pcl_df.index.duplicated()].unique()\n",
    "            \n",
    "            if len(duplicate_indexes) > 1000:\n",
    "                print(f\"File: {file_name}\")\n",
    "                print(f\"Number of duplicate indexes: {len(duplicate_indexes)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Direct duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing PCL files\n",
    "pcl_directory = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls\"\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Rename index to \"YORF\"\n",
    "            pcl_df.index.name = \"YORF\"\n",
    "\n",
    "            # Identify experimental columns (excluding NAME and GWEIGHT)\n",
    "            experimental_cols = [col for col in pcl_df.columns if col not in [\"NAME\", \"GWEIGHT\"]]\n",
    "\n",
    "            # Reset index to include the YORF in duplicate detection\n",
    "            pcl_df_reset = pcl_df.reset_index()\n",
    "\n",
    "            # Detect exact duplicates (same YORF and experimental values)\n",
    "            duplicate_mask = pcl_df_reset.duplicated(subset=[\"YORF\"] + experimental_cols, keep=False)\n",
    "\n",
    "            # Filter duplicated rows\n",
    "            duplicate_df = pcl_df_reset[duplicate_mask]\n",
    "\n",
    "            if not duplicate_df.empty:\n",
    "                print(f\"\\nDuplicates found in {file_name}:\")\n",
    "                duplicate_genes = duplicate_df[\"YORF\"].unique()\n",
    "                print(f\"Duplicate genes: {', '.join(duplicate_genes)}\")\n",
    "                #print(duplicate_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing PCL files\n",
    "pcl_directory = \"/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls\"\n",
    "\n",
    "# Iterate over each .pcl file in the directory\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "\n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "\n",
    "            # Rename index to \"YORF\"\n",
    "            pcl_df.index.name = \"YORF\"\n",
    "\n",
    "            # Identify experimental columns (excluding NAME and GWEIGHT)\n",
    "            experimental_cols = [col for col in pcl_df.columns if col not in [\"NAME\", \"GWEIGHT\"]]\n",
    "\n",
    "            # Reset index for duplicate detection\n",
    "            pcl_df_reset = pcl_df.reset_index()\n",
    "\n",
    "            # Drop exact duplicates (same index and same experimental values)\n",
    "            pcl_df_cleaned = pcl_df_reset.drop_duplicates(subset=[\"YORF\"] + experimental_cols, keep=\"first\")\n",
    "\n",
    "            # Save back to the original file\n",
    "            pcl_df_cleaned.to_csv(pcl_file_path, sep='\\t', index=False)\n",
    "\n",
    "            print(f\"✅ Cleaned duplicates from {file_name}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pseudoduplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/test_pcls'\n",
    "\n",
    "# Track first pseudoduplicate group\n",
    "first_pseudoduplicate_printed = False\n",
    "\n",
    "# Iterate over all .pcl files\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify experimental columns (excluding NAME and GWEIGHT)\n",
    "            experimental_cols = [col for col in pcl_df.columns if col not in [\"NAME\", \"GWEIGHT\"]]\n",
    "            \n",
    "            # Count pseudoduplicates\n",
    "            duplicate_groups = pcl_df.groupby(pcl_df.index)\n",
    "\n",
    "            pseudoduplicate_count = 0\n",
    "            first_pseudoduplicate_family = None\n",
    "\n",
    "            for yorf, group in duplicate_groups:\n",
    "                if len(group) > 1:\n",
    "                    unique_experiment_values = group[experimental_cols].drop_duplicates()\n",
    "                    \n",
    "                    if len(unique_experiment_values) > 1:\n",
    "                        pseudoduplicate_count += 1\n",
    "                        \n",
    "                        # Store the first pseudoduplicate group if not printed yet\n",
    "                        if not first_pseudoduplicate_printed:\n",
    "                            first_pseudoduplicate_family = group\n",
    "                            first_pseudoduplicate_printed = None\n",
    "            \n",
    "            # Print count for the file if there are pseudoduplicates\n",
    "            if pseudoduplicate_count > 0:\n",
    "                print(f\"File: {file_name} - Pseudoduplicate YORFs: {pseudoduplicate_count}\")\n",
    "                \n",
    "                # Print the first found pseudoduplicate family\n",
    "                if first_pseudoduplicate_family is not None:\n",
    "                    print(\"\\nFirst Pseudoduplicate Family:\")\n",
    "                    print(first_pseudoduplicate_family.index)\n",
    "                    print(\"-----------------------------------\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "done = 0\n",
    "\n",
    "# Iterate over all .pcl files\n",
    "for file_name in os.listdir(pcl_directory):\n",
    "    if done:\n",
    "        break\n",
    "    if file_name.endswith(\".pcl\"):\n",
    "        pcl_file_path = os.path.join(pcl_directory, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Load the PCL file\n",
    "            pcl_df = pd.read_csv(pcl_file_path, sep='\\t', index_col=0)\n",
    "            \n",
    "            # Identify experimental columns (excluding NAME and GWEIGHT)\n",
    "            experimental_cols = [col for col in pcl_df.columns if col not in [\"NAME\", \"GWEIGHT\"]]\n",
    "            \n",
    "            # Count pseudoduplicates\n",
    "            duplicate_groups = pcl_df.groupby(pcl_df.index)\n",
    "            \n",
    "            for gene, group in duplicate_groups:\n",
    "                if len(group) >= 3:  # 3 or more pseudoduplicates\n",
    "                    print(f\"File: {file_name} - Gene: {gene}\")\n",
    "                    done = True\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file '{file_name}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fixing the Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def load_pcl(file_path):\n",
    "    \"\"\"Loads a .pcl file into a Pandas DataFrame, using the first column as the index.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "        df.drop(columns=['NAME', 'GWEIGHT'], errors='ignore', inplace=True)  # Ignore if not present\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file '{file_path}': {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_correlation_matrix(group):\n",
    "    \"\"\"Computes the correlation matrix for a group of pseudoduplicates.\"\"\"\n",
    "    return group.T.corr()\n",
    "\n",
    "def merge_pseudoduplicates(group, threshold=0.8):\n",
    "    \"\"\"Merges correlated pseudoduplicates and selects one if uncorrelated remain.\"\"\"\n",
    "    if len(group) == 1:\n",
    "        return group  # Only one row, no duplicates\n",
    "    \n",
    "    corr_matrix = compute_correlation_matrix(group)\n",
    "    merged_rows = []\n",
    "    used = set()\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        if i in used:\n",
    "            continue\n",
    "        correlated = [i]\n",
    "        \n",
    "        for j in range(i + 1, len(group)):\n",
    "            if j not in used and corr_matrix.iloc[i, j] >= threshold:\n",
    "                correlated.append(j)\n",
    "                used.add(j)\n",
    "        \n",
    "        merged_rows.append(group.iloc[correlated].mean())\n",
    "        used.add(i)\n",
    "    \n",
    "    if len(merged_rows) > 1:\n",
    "        return pd.DataFrame([merged_rows[np.random.choice(len(merged_rows))]])  # Pick one randomly\n",
    "    \n",
    "    return pd.DataFrame(merged_rows)  # Return merged row\n",
    "\n",
    "def process_pcl_files(pcl_directory, output_directory):\n",
    "    \"\"\"Processes all .pcl files in the directory, cleans pseudoduplicates, and saves results.\"\"\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(pcl_directory):\n",
    "        if filename.endswith(\".pcl\"):\n",
    "            file_path = os.path.join(pcl_directory, filename)\n",
    "            df = load_pcl(file_path)\n",
    "            \n",
    "            if df is None:\n",
    "                continue\n",
    "            \n",
    "            # Identify experimental columns\n",
    "            experimental_cols = [col for col in df.columns if col not in [\"NAME\", \"GWEIGHT\"]]\n",
    "            df = df[experimental_cols]  # Keep only experimental columns\n",
    "            \n",
    "            cleaned_data = []\n",
    "            duplicate_groups = df.groupby(df.index)\n",
    "            \n",
    "            for gene, group in duplicate_groups:\n",
    "                cleaned_group = merge_pseudoduplicates(group)\n",
    "                cleaned_group.index = [gene] * len(cleaned_group)  # Keep original index\n",
    "                cleaned_data.append(cleaned_group)\n",
    "            \n",
    "            cleaned_df = pd.concat(cleaned_data)\n",
    "            output_path = os.path.join(output_directory, filename)\n",
    "            cleaned_df.to_csv(output_path, sep='\\t')\n",
    "            print(f\"Processed: {filename} -> {output_path}\")\n",
    "\n",
    "# Set directories\n",
    "pcl_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "output_directory = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/all_pcls'\n",
    "\n",
    "# Run processing\n",
    "process_pcl_files(pcl_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 11889)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '/home/logs/jtorresb/Geneformer/yeast/yeast_data/output/unnormalized_yeast_master_matrix_sgd.csv'\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t', index_col=0)\n",
    "\n",
    "print(df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geneformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
